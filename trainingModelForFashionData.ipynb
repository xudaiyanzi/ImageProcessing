{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation - Normalization\n",
    "* Here, we select the \"Fashion MNIST\" image dataset from Keras to practice the model training\n",
    "* Normalize the pixel value ranges from 0-255 to 0-1, which reducing the compuation complexity# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the training data and testing data\n",
    "# no validation data in this dataset by default - Keras provides only the training and test splits. \n",
    "# However, you can create a validation set yourself by splitting the training data.\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As the fashion_mnist dataset has 10 categories: T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
    "- Class labels as integers (e.g., 0, 1, 2, ..., 9), and are converted into one-hot encoded vectors using the to_categorical function\n",
    "- One-hot encoding represents each class as a binary vector of size equal to the number of classes:\n",
    "    - Neural networks often work better with one-hot encoded labels when training on classification tasks because the output layer typically has the same number of nodes as the number of classes. One-hot encoding allows the model to compute probabilities for each class during training.\n",
    "    - for example:\n",
    "         - [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # Corresponds to class 0\n",
    "         - [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],  # Corresponds to class 1\n",
    "         - [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],  # Corresponds to class 2\n",
    "         - [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]]  # Corresponds to class 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = keras.utils.to_categorical(train_labels, 10) \n",
    "test_labels = keras.utils.to_categorical(test_labels, 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create convolutional neewral network model using Keras Sequential API\n",
    "- Sequential model stacked in a linear order, where the output of one layer serves as the input for the next\n",
    "- Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)), meaning \n",
    "  - 2D convolutional layer with 32 filters\n",
    "  - each filiter has the size of 3*3\n",
    "  - activation function 'ReLu' introduce non-linearity\n",
    "  - input image is 32*32 pixels with 1 color channel, if it is 3 then it is 3 color channels - RGB\n",
    "- MaxPooling2D((2, 2)):\n",
    "  - Down-samples the feature mapy by taking the maximum value in each 2*2 region\n",
    "  - (2,2) is the pool size, reducing hte spatial dimensions by a factor of 2\n",
    "  - as a result, the smaller feature maps reduces the computational complexity\n",
    "- more Conv2D() functions helps to extract even more complex features\n",
    "- more maxPooling2D() functions reduce spatial dimentions, retaining the most importa features\n",
    "- Flatten(): converts the multi-dimentsional feature maps into a 1D vector, preparing them for the dense layers\n",
    "- Dense(64, activation='relu'): fully connected layer with 64 neurons\n",
    "- Dense(64, activation='softmax'): 10 neurons, and softmax activation functions ensures the output probabilities for each class sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile and train the model\n",
    "\n",
    "- model.compileL sets up the optimizer, loss function, and metrics for training\n",
    "    - optimizer 'adam': adaptive moment estimation is an advanced optimization algorithm that combines the benefits of RMSPro an SGD with momentum\n",
    "        - it adjuts the learning rate for each parameter dynamically based on first and second moments of gradients\n",
    "        - it is good for minimal tuning, and handles sparse gradients effectively\n",
    "    - loss function 'catagorical_crossentropy': \n",
    "        - used for multi-classification with one-hot encoded labels\n",
    "        - compute the difference between the predicted probability distribution from the softmax layer and the true label distribution\n",
    "    - metrics 'accuracy': measures the percentage of correctly classified samples\n",
    "\n",
    "- model.fit trains the model for the specific number of epochs using mini-batches of data\n",
    "    - epoches=10: \n",
    "        - Specifies the number of complete passes through the entire training dataset.\n",
    "        - During each epoch, the model updates its weights based on the loss and optimizer.\n",
    "    - batch_size=64:\n",
    "        - Defines the number of samples processed before the model updates its weights.\n",
    "            - Smaller batch sizes: Provide faster feedback but noisier updates.\n",
    "            - Larger batch sizes: Offer smoother updates but require more memory.\n",
    "        - without specifing the size, the default size would be 32\n",
    "\n",
    "- model learns to minimize the loss function, improving the accuracy over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7651 - loss: 0.6577\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8841 - loss: 0.3215\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8995 - loss: 0.2731\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9125 - loss: 0.2378\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.2104\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9305 - loss: 0.1908\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9363 - loss: 0.1742\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9432 - loss: 0.1532\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9479 - loss: 0.1393\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9534 - loss: 0.1222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13f5b8200>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.3131\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageProcess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
